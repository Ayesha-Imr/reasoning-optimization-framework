### **Documentation: Completion of Step 1 - Hallucination Vector Generation**

**Objective:** To computationally identify and save a single vector, `v_halluc`, representing the direction of "hallucination" within the activation space of the Llama 3 8B Instruct model.

**Outcome:** This step has been successfully completed. The primary artifact, `v_halluc.pt`, has been generated and saved to the project's Google Drive.

---

#### **Summary of Process and Methodology**

The vector was generated by faithfully implementing the **Î”-Means (mean-difference)** methodology from the "Persona Vectors" paper, adapted for our specific constraints and goals. The process was executed in a single Google Colab notebook and can be broken down into four distinct phases:

**Phase 1: Setup and Data Preparation**
*   The environment was configured in Google Colab, with all necessary libraries (`unsloth`, `transformers`, `torch`, etc.) installed.
*   API keys for Hugging Face and the `scaledown.xyz` (Gemini) service were securely loaded.
*   The foundational dataset, `hallucinating.json`, was loaded and parsed using the `load_and_parse_trait_data` function, yielding lists of positive (eliciting) and negative (suppressing) system prompts, and a list of factual questions.

**Phase 2: First Pass - Generation and Judging**
*   The `unsloth/llama-3-8b-Instruct-bnb-4bit` model was loaded in 4-bit precision.
*   A custom judge function, `get_judge_score`, was implemented to query the Gemini 1.5 Flash API and score model answers for `hallucination` and `coherence`.
*   A resilient, batched loop was executed. For each of the 20 factual questions, the model generated two answers: one under a randomly chosen eliciting prompt and one under a suppressing prompt.
*   All 40 answers were scored by the Gemini judge. The results, including prompts, answers, and scores, were saved progressively to `judged_answers.csv` in Google Drive.

**Phase 3: Second Pass - Activation Extraction**
*   The `judged_answers.csv` file was loaded, and a strict filter was applied to isolate **16 "effective pairs"**. These pairs met the criteria of high hallucination/coherence for the positive response and low hallucination/high coherence for the negative response.
*   A specialized function, `extract_layer_16_activations`, was implemented. This function runs a given prompt-answer pair through the model and extracts the mean activation of the response tokens specifically from the pre-selected **`TARGET_LAYER = 16`**.
*   A resilient loop processed these 16 effective pairs, saving the 32 resulting Layer 16 activation tensors individually to `activations/positive/` and `activations/negative/` directories on Google Drive.

**Phase 4: Final Vector Computation**
*   The 16 activation tensors from the `positive` directory were loaded and averaged into a single tensor using the `average_activations_from_dir` function.
*   The same was done for the 16 tensors in the `negative` directory.
*   The final **hallucination persona vector** was computed by subtracting the mean negative activations from the mean positive activations.
*   The resulting 1D tensor was saved as `v_halluc.pt`.

---

#### **Key Artifacts and Constants**

*   **Primary Artifact:**
    *   **File:** `v_halluc.pt`
    *   **Location:** `/content/drive/MyDrive/HallucinationVectorProject/`
    *   **Description:** A PyTorch tensor of shape `[4096]` and dtype `torch.float16` representing the hallucination direction at Layer 16.
*   **Intermediate Artifact:**
    *   **File:** `judged_answers.csv`
    *   **Location:** `/content/drive/MyDrive/HallucinationVectorProject/`
    *   **Description:** A CSV file containing the generated positive/negative answers and their corresponding judge scores for all 20 initial questions.
*   **Key Constants Used:**
    *   **Model:** `unsloth/llama-3-8b-Instruct-bnb-4bit`
    *   **Target Layer:** `TARGET_LAYER = 16`
    *   **Judge Model:** `gemini-1.5-flash-latest` (via `scaledown.xyz` API)
    *   **Filtering Thresholds:**
        *   `POS_HALLUCINATION_THRESHOLD = 50`
        *   `NEG_HALLUCINATION_THRESHOLD = 50`
        *   `COHERENCE_THRESHOLD = 50`

#### **Defined Functions**

*   `load_and_parse_trait_data(file_path)`: Loaded and parsed the initial JSON data.
*   `get_judge_score(question, answer, judge_type, api_key)`: Queried the Gemini API to score model outputs.
*   `generate_answer(system_prompt, user_question)`: A helper to generate text from the Llama 3 model.
*   `extract_layer_16_activations(...)`: The core function to run the model and extract the hidden states from the target layer.
*   `average_activations_from_dir(directory_path)`: Loaded and averaged the saved `.pt` activation files.

This completes the documentation for Step 1. We have successfully replicated the paper's vector generation methodology in a simplified, resilient workflow and produced the core `v_halluc` vector required for the subsequent steps of the project.